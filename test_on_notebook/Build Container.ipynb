{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Docker File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM python:3.6\r\n",
      "\r\n",
      "RUN apt-get -y update && apt-get install -y --no-install-recommends \\\r\n",
      "         wget \\\r\n",
      "         python \\\r\n",
      "         nginx \\\r\n",
      "         ca-certificates \\\r\n",
      "    && rm -rf /var/lib/apt/lists/*\r\n",
      "\r\n",
      "# Install all of the packages\r\n",
      "RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py\r\n",
      "\r\n",
      "# install code dependencies\r\n",
      "COPY \"requirements.txt\" .\r\n",
      "RUN [\"pip\", \"install\", \"-r\", \"requirements.txt\"]\r\n",
      "\r\n",
      "RUN pip list\r\n",
      "# Env Variables\r\n",
      "ENV PYTHONUNBUFFERED=TRUE\r\n",
      "ENV PYTHONDONTWRITEBYTECODE=TRUE\r\n",
      "ENV PATH=\"/opt/ml:${PATH}\"\r\n",
      "\r\n",
      "# Set up the program in the image\r\n",
      "COPY scripts /opt/ml\r\n",
      "WORKDIR /opt/ml\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# Main Libraries used:\r\n",
      "\r\n",
      "# RUN pip install numpy\r\n",
      "# RUN pip install scipy\r\n",
      "# RUN pip install scikit-learn\r\n",
      "# RUN pip install pandas\r\n",
      "# RUN pip install flask\r\n",
      "# RUN pip install gevent\r\n",
      "# RUN pip install gunicorn\r\n",
      "# RUN pip install tensorflow==1.15.2\r\n",
      "# RUN pip install keras==2.2.4\r\n",
      "# RUN pip install h5py\r\n",
      "# RUN pip install hyperopt\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and registering the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  56.83kB\r",
      "\r\n",
      "Step 1/11 : FROM python:3.6\n",
      " ---> 3cfab35f43d8\n",
      "Step 2/11 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          python          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> b75d4cd4a101\n",
      "Step 3/11 : RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py\n",
      " ---> Using cache\n",
      " ---> b4aaf23f847d\n",
      "Step 4/11 : COPY \"requirements.txt\" .\n",
      " ---> Using cache\n",
      " ---> 05ac400095c3\n",
      "Step 5/11 : RUN [\"pip\", \"install\", \"-r\", \"requirements.txt\"]\n",
      " ---> Using cache\n",
      " ---> b47f4eb1a88a\n",
      "Step 6/11 : RUN pip list\n",
      " ---> Using cache\n",
      " ---> d062397de672\n",
      "Step 7/11 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> b0d23f10a547\n",
      "Step 8/11 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> f2a7938ad223\n",
      "Step 9/11 : ENV PATH=\"/opt/ml:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 75555c546dca\n",
      "Step 10/11 : COPY scripts /opt/ml\n",
      " ---> Using cache\n",
      " ---> 6af50d7af3ee\n",
      "Step 11/11 : WORKDIR /opt/ml\n",
      " ---> Using cache\n",
      " ---> a9b17f52b8b4\n",
      "Successfully built a9b17f52b8b4\n",
      "Successfully tagged dnn:latest\n",
      "The push refers to repository [597844091762.dkr.ecr.us-east-1.amazonaws.com/dnn]\n",
      "b63286135a96: Preparing\n",
      "af0e54d0d3d9: Preparing\n",
      "b1df4cf87af9: Preparing\n",
      "0364717da780: Preparing\n",
      "754dad28cdad: Preparing\n",
      "698d65bfd862: Preparing\n",
      "57ea26d7c419: Preparing\n",
      "03bf090723cb: Preparing\n",
      "ca95e3645a5b: Preparing\n",
      "a91085dfed16: Preparing\n",
      "cfb4ccdac258: Preparing\n",
      "46a297e68c47: Preparing\n",
      "cf47dfabe081: Preparing\n",
      "c53d956ebfec: Preparing\n",
      "6086e1b289d9: Preparing\n",
      "ca95e3645a5b: Waiting\n",
      "a91085dfed16: Waiting\n",
      "cfb4ccdac258: Waiting\n",
      "46a297e68c47: Waiting\n",
      "cf47dfabe081: Waiting\n",
      "c53d956ebfec: Waiting\n",
      "6086e1b289d9: Waiting\n",
      "57ea26d7c419: Waiting\n",
      "03bf090723cb: Waiting\n",
      "698d65bfd862: Waiting\n",
      "b63286135a96: Pushed\n",
      "0364717da780: Pushed\n",
      "af0e54d0d3d9: Pushed\n",
      "03bf090723cb: Pushed\n",
      "754dad28cdad: Pushed\n",
      "698d65bfd862: Pushed\n",
      "57ea26d7c419: Pushed\n",
      "a91085dfed16: Pushed\n",
      "ca95e3645a5b: Pushed\n",
      "cf47dfabe081: Pushed\n",
      "c53d956ebfec: Pushed\n",
      "6086e1b289d9: Pushed\n",
      "46a297e68c47: Pushed\n",
      "cfb4ccdac258: Pushed\n",
      "b1df4cf87af9: Pushed\n",
      "latest: digest: sha256:ee7a5332ed41f5671dc826f5166dd3f4d918057ba92d8325b364d916bec16cf2 size: 3477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=dnn\n",
    "\n",
    "cd ../container\n",
    "\n",
    "chmod +x scripts/train\n",
    "chmod +x scripts/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the container from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = 'dnn'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.session.Session at 0x7f20bcdc1780>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-597844091762/dnn'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE dnn-2020-07-31-23-40-40-767/\r\n",
      "                           PRE dnn-2020-08-01-16-49-56-395/\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://sagemaker-us-east-1-597844091762/dnn/output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an estimator and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !container/local_test/train_local.sh ann-churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage.estimator.Estimator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = f'{account}.dkr.ecr.{region}.amazonaws.com/{prefix}:latest'\n",
    "\n",
    "clf = sage.estimator.Estimator(\n",
    "    image, \n",
    "    role, \n",
    "    2, \n",
    "    'ml.m4.2xlarge',\n",
    "    output_path=\"s3://{}/{}/output\".format(sess.default_bucket(), prefix),\n",
    "    sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training = True\n",
    "\n",
    "if final_training: # Final Training\n",
    "    clf.set_hyperparameters(final_training = True,\n",
    "                            target = 'Target',# arbitrary string\n",
    "                            batch_normalization = True,\n",
    "                            include_dropout = True,\n",
    "                            dropout_f = .2,\n",
    "                            early_stopping_patience = 15,# Number of epochs with no significant change in metric before early stopping happens \n",
    "                            lr_update_patience = 7,\n",
    "                            loss_metric = 'mae',\n",
    "                            monitor_metric = 'val_mean_absolute_error',\n",
    "                            num_layers_f = 8,\n",
    "                            nodes = [1024,64,1024,32,32,64,512], # The number of nodes (length of \"nodes\" list) should be num_layers_f-1 because the last layer has 1 node and is automatically added\n",
    "                            nb_epochs_f = 300,\n",
    "                            batch_size_f = 32,\n",
    "                            optimizer_f = 'adam',\n",
    "                            last_activation_f = 'tanh'\n",
    "                           )    \n",
    "else:  # HPO\n",
    "    clf.set_hyperparameters(final_training = False,\n",
    "                            target = 'Target',# arbitrary string\n",
    "                            batch_normalization = True,\n",
    "                            include_dropout = False,\n",
    "                            dropout = [.2,.3,.5],\n",
    "                            early_stopping_patience = 15,# Number of epochs with no significant change in metric before early stopping happens \n",
    "                            lr_update_patience = 7,# Number of epochs with no significant change in metric before learning rate decrease\n",
    "                            loss_metric = 'mae',\n",
    "                            monitor_metric = 'val_mean_absolute_error',\n",
    "                            used_data_percentage = 10,\n",
    "                            train_validation_split = .15,\n",
    "                            MAX_EVALS = 3,\n",
    "                            randstate = 50,\n",
    "                            num_layers_low = 1,\n",
    "                            num_layers_high = 9,\n",
    "                            choice_of_node_numbers = [16,32,64,128,256,512,1024,2048], # Here you can give the possible node size for layers. If you want to only have small number of nodes, remove the high values from this list. \n",
    "                            nb_epochs = 3,\n",
    "                            batch_size = [32,64,128],\n",
    "                            optimizer = ['adam'],\n",
    "                            last_activation = ['tanh']  # Activation for the layer with one node. Options for this are 'linear' and 'tanh'\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-28 19:56:13 Starting - Starting the training job...\n",
      "2020-08-28 19:56:16 Starting - Launching requested ML instances...............\n",
      "2020-08-28 19:59:08 Starting - Preparing the instances for training......\n",
      "2020-08-28 20:00:12 Downloading - Downloading input data...\n",
      "2020-08-28 20:00:40 Training - Downloading the training image......\n",
      "2020-08-28 20:01:38 Training - Training image download completed. Training in progress..\u001b[34mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mStarting the final training...\u001b[0m\n",
      "\u001b[34mIndex(['F0', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10',\n",
      "       'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20',\n",
      "       'F21', 'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'Target'],\n",
      "      dtype='object')\u001b[0m\n",
      "\u001b[34mdata loaded\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mdense_1 (Dense)              (None, 1024)              29696     \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_1 (Batch (None, 1024)              4096      \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_1 (Dropout)          (None, 1024)              0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_2 (Dense)              (None, 64)                65600     \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_2 (Batch (None, 64)                256       \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_2 (Dropout)          (None, 64)                0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_3 (Dense)              (None, 1024)              66560     \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_3 (Batch (None, 1024)              4096      \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_3 (Dropout)          (None, 1024)              0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_4 (Dense)              (None, 32)                32800     \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_4 (Batch (None, 32)                128       \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_4 (Dropout)          (None, 32)                0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_5 (Dense)              (None, 32)                1056      \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_5 (Batch (None, 32)                128       \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_5 (Dropout)          (None, 32)                0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_6 (Dense)              (None, 64)                2112      \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_6 (Batch (None, 64)                256       \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_6 (Dropout)          (None, 64)                0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_7 (Dense)              (None, 512)               33280     \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_7 (Batch (None, 512)               2048      \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_7 (Dropout)          (None, 512)               0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_8 (Dense)              (None, 1)                 513       \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_8 (Batch (None, 1)                 4         \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 242,629\u001b[0m\n",
      "\u001b[34mTrainable params: 237,123\u001b[0m\n",
      "\u001b[34mNon-trainable params: 5,506\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\u001b[0m\n",
      "\u001b[34mTrain on 8500 samples, validate on 1500 samples\u001b[0m\n",
      "\u001b[34mEpoch 1/300\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\u001b[0m\n",
      "\u001b[34m - 4s - loss: 0.5982 - mean_absolute_error: 0.5982 - val_loss: 0.2542 - val_mean_absolute_error: 0.2542\u001b[0m\n",
      "\u001b[34mEpoch 2/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2697 - mean_absolute_error: 0.2697 - val_loss: 0.2535 - val_mean_absolute_error: 0.2535\u001b[0m\n",
      "\u001b[34mEpoch 3/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2473 - mean_absolute_error: 0.2473 - val_loss: 0.2527 - val_mean_absolute_error: 0.2527\u001b[0m\n",
      "\u001b[34mEpoch 4/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2472 - mean_absolute_error: 0.2472 - val_loss: 0.2526 - val_mean_absolute_error: 0.2526\u001b[0m\n",
      "\u001b[34mEpoch 5/300\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[35mStarting the training.\u001b[0m\n",
      "\u001b[35mStarting the final training...\u001b[0m\n",
      "\u001b[35mIndex(['F0', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10',\n",
      "       'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20',\n",
      "       'F21', 'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'Target'],\n",
      "      dtype='object')\u001b[0m\n",
      "\u001b[35mdata loaded\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[35m=================================================================\u001b[0m\n",
      "\u001b[35mdense_1 (Dense)              (None, 1024)              29696     \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mbatch_normalization_1 (Batch (None, 1024)              4096      \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mdropout_1 (Dropout)          (None, 1024)              0         \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mdense_2 (Dense)              (None, 64)                65600     \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mbatch_normalization_2 (Batch (None, 64)                256       \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mdropout_2 (Dropout)          (None, 64)                0         \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mdense_3 (Dense)              (None, 1024)              66560     \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mbatch_normalization_3 (Batch (None, 1024)              4096      \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mdropout_3 (Dropout)          (None, 1024)              0         \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mdense_4 (Dense)              (None, 32)                32800     \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mbatch_normalization_4 (Batch (None, 32)                128       \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mdropout_4 (Dropout)          (None, 32)                0         \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mdense_5 (Dense)              (None, 32)                1056      \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mbatch_normalization_5 (Batch (None, 32)                128       \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mdropout_5 (Dropout)          (None, 32)                0         \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mdense_6 (Dense)              (None, 64)                2112      \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mbatch_normalization_6 (Batch (None, 64)                256       \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mdropout_6 (Dropout)          (None, 64)                0         \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mdense_7 (Dense)              (None, 512)               33280     \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mbatch_normalization_7 (Batch (None, 512)               2048      \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mdropout_7 (Dropout)          (None, 512)               0         \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mdense_8 (Dense)              (None, 1)                 513       \u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mbatch_normalization_8 (Batch (None, 1)                 4         \u001b[0m\n",
      "\u001b[35m=================================================================\u001b[0m\n",
      "\u001b[35mTotal params: 242,629\u001b[0m\n",
      "\u001b[35mTrainable params: 237,123\u001b[0m\n",
      "\u001b[35mNon-trainable params: 5,506\u001b[0m\n",
      "\u001b[35m_________________________________________________________________\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\u001b[0m\n",
      "\u001b[35mTrain on 8500 samples, validate on 1500 samples\u001b[0m\n",
      "\u001b[35mEpoch 1/300\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\u001b[0m\n",
      "\u001b[35m - 4s - loss: 0.5784 - mean_absolute_error: 0.5784 - val_loss: 0.2459 - val_mean_absolute_error: 0.2459\u001b[0m\n",
      "\u001b[35mEpoch 2/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2674 - mean_absolute_error: 0.2674 - val_loss: 0.2445 - val_mean_absolute_error: 0.2445\u001b[0m\n",
      "\u001b[35mEpoch 3/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2490 - mean_absolute_error: 0.2490 - val_loss: 0.2437 - val_mean_absolute_error: 0.2437\u001b[0m\n",
      "\u001b[35mEpoch 4/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2484 - mean_absolute_error: 0.2484 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mEpoch 5/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2484 - mean_absolute_error: 0.2484 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mEpoch 6/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2468 - mean_absolute_error: 0.2468 - val_loss: 0.2526 - val_mean_absolute_error: 0.2526\u001b[0m\n",
      "\u001b[34mEpoch 6/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2482 - mean_absolute_error: 0.2482 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mEpoch 7/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2466 - mean_absolute_error: 0.2466 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 7/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2484 - mean_absolute_error: 0.2484 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mEpoch 8/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2467 - mean_absolute_error: 0.2467 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 8/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2486 - mean_absolute_error: 0.2486 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mEpoch 9/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2467 - mean_absolute_error: 0.2467 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 9/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2490 - mean_absolute_error: 0.2490 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mEpoch 10/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2467 - mean_absolute_error: 0.2467 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 10/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2483 - mean_absolute_error: 0.2483 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mEpoch 11/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2467 - mean_absolute_error: 0.2467 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 11/300\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m - 2s - loss: 0.2483 - mean_absolute_error: 0.2483 - val_loss: 0.2435 - val_mean_absolute_error: 0.2435\n",
      "\u001b[0m\n",
      "\u001b[35mEpoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\u001b[0m\n",
      "\u001b[35mEpoch 12/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2467 - mean_absolute_error: 0.2467 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 12/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2482 - mean_absolute_error: 0.2482 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mEpoch 13/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2466 - mean_absolute_error: 0.2466 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 13/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2482 - mean_absolute_error: 0.2482 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mEpoch 14/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2467 - mean_absolute_error: 0.2467 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\u001b[0m\n",
      "\u001b[34mEpoch 14/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2483 - mean_absolute_error: 0.2483 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mEpoch 15/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2466 - mean_absolute_error: 0.2466 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 15/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2483 - mean_absolute_error: 0.2483 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mEpoch 16/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2466 - mean_absolute_error: 0.2466 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 16/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2482 - mean_absolute_error: 0.2482 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mEpoch 17/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2466 - mean_absolute_error: 0.2466 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 17/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2482 - mean_absolute_error: 0.2482 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mEpoch 18/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2466 - mean_absolute_error: 0.2466 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 18/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2482 - mean_absolute_error: 0.2482 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\n",
      "\u001b[0m\n",
      "\u001b[35mEpoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\u001b[0m\n",
      "\u001b[35mEpoch 19/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2466 - mean_absolute_error: 0.2466 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 19/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2482 - mean_absolute_error: 0.2482 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mEpoch 20/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2466 - mean_absolute_error: 0.2466 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 20/300\u001b[0m\n",
      "\u001b[35m - 2s - loss: 0.2482 - mean_absolute_error: 0.2482 - val_loss: 0.2434 - val_mean_absolute_error: 0.2434\u001b[0m\n",
      "\u001b[35mSaved model to disk\u001b[0m\n",
      "\u001b[35mq95  7.5702462673187245\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2466 - mean_absolute_error: 0.2466 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\u001b[0m\n",
      "\u001b[34mEpoch 21/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2466 - mean_absolute_error: 0.2466 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 22/300\u001b[0m\n",
      "\n",
      "2020-08-28 20:02:46 Uploading - Uploading generated training model\n",
      "2020-08-28 20:02:46 Completed - Training job completed\n",
      "\u001b[34m - 2s - loss: 0.2466 - mean_absolute_error: 0.2466 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mEpoch 23/300\u001b[0m\n",
      "\u001b[34m - 2s - loss: 0.2466 - mean_absolute_error: 0.2466 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\u001b[0m\n",
      "\u001b[34mSaved model to disk\u001b[0m\n",
      "\u001b[34mq95  7.530184650421134\u001b[0m\n",
      "Training seconds: 308\n",
      "Billable seconds: 308\n"
     ]
    }
   ],
   "source": [
    "clf.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "# 'ml.m4.2xlarge\n",
    "predictor = clf.deploy(1, 'ml.t2.medium', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Inference using your endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4543851\n",
      "0.4524969\n",
      "-2.281816\n",
      "-2.3425076\n",
      "-1.1159251\n",
      "0.7206936\n",
      "0.44174922\n",
      "-2.0166993\n",
      "0.3614421\n",
      "0.40492582\n",
      "0.86388576\n",
      "0.45966506\n",
      "0.88729477\n",
      "-1.9939917\n",
      "-2.505851\n",
      "-1.0132473\n",
      "-1.5082275\n",
      "0.5550299\n",
      "0.8951546\n",
      "0.48231643\n",
      "-0.1171655\n",
      "0.8137144\n",
      "0.8104975\n",
      "0.4096722\n",
      "-0.38626385\n",
      "0.56806266\n",
      "0.49516064\n",
      "0.79760003\n",
      "-2.5226\n",
      "-2.169464\n",
      "0.47764283\n",
      "1.0997182\n",
      "0.62332654\n",
      "0.47557318\n",
      "0.31022048\n",
      "1.1103781\n",
      "-0.29530275\n",
      "-0.3499143\n",
      "0.80459535\n",
      "0.6170493\n",
      "0.5890228\n",
      "0.9398215\n",
      "0.44568592\n",
      "-0.33819556\n",
      "0.7365062\n",
      "0.37853813\n",
      "0.5786757\n",
      "1.1121311\n",
      "0.44373238\n",
      "0.4494444\n",
      "0.7082635\n",
      "-2.5089495\n",
      "0.9290234\n",
      "0.6302534\n",
      "0.58756155\n",
      "0.87174547\n",
      "1.0767252\n",
      "-0.62279314\n",
      "0.6430147\n",
      "0.72513914\n",
      "0.81923306\n",
      "0.44854695\n",
      "0.92391276\n",
      "-0.40077397\n",
      "0.7643955\n",
      "-0.50616145\n",
      "0.29813856\n",
      "0.48851758\n",
      "0.53562343\n",
      "0.41239822\n",
      "0.9418725\n",
      "0.6214094\n",
      "0.46062738\n",
      "0.7342822\n",
      "0.9403086\n",
      "0.5665387\n",
      "1.1065239\n",
      "0.69793737\n",
      "0.57264584\n",
      "0.40309596\n",
      "0.91506934\n",
      "0.4914052\n",
      "0.658716\n",
      "0.5392608\n",
      "0.39463478\n",
      "0.5623907\n",
      "0.7149785\n",
      "0.38935357\n",
      "0.8153\n",
      "0.659692\n",
      "0.9099002\n",
      "0.7353129\n",
      "0.7275145\n",
      "0.48609346\n",
      "0.45560187\n",
      "0.46547788\n",
      "0.43797696\n",
      "0.55956507\n",
      "-2.490685\n",
      "0.35533476\n",
      "1.3221327\n",
      "1.1140968\n",
      "0.42015946\n",
      "0.7463349\n",
      "0.9089595\n",
      "0.6534643\n",
      "0.40732622\n",
      "-2.5269694\n",
      "0.80622816\n",
      "0.75155056\n",
      "-1.3774723\n",
      "0.3510272\n",
      "-0.5941835\n",
      "0.8984034\n",
      "0.5613341\n",
      "0.77836436\n",
      "0.43344164\n",
      "0.7730056\n",
      "0.8211119\n",
      "0.50985414\n",
      "-1.2901123\n",
      "0.43049657\n",
      "-2.0764337\n",
      "0.52633274\n",
      "0.6391627\n",
      "0.4144994\n",
      "-2.0656495\n",
      "-0.67473394\n",
      "0.5233232\n",
      "0.77497905\n",
      "0.659634\n",
      "0.43465877\n",
      "-2.0060349\n",
      "0.9587909\n",
      "0.8091577\n",
      "0.29034978\n",
      "-2.5241458\n",
      "0.8983779\n",
      "-1.5468062\n",
      "0.547228\n",
      "0.5422727\n",
      "0.50917536\n",
      "0.9020325\n",
      "0.7880113\n",
      "0.6971269\n",
      "0.6173474\n",
      "0.8219328\n",
      "0.9894093\n",
      "1.0355787\n",
      "0.17724225\n",
      "0.9472691\n",
      "0.38214743\n",
      "0.47937274\n",
      "0.67746234\n",
      "0.7876073\n",
      "0.7416639\n",
      "-1.0372932\n",
      "0.7888027\n",
      "0.6323103\n",
      "0.43608367\n",
      "0.6640822\n",
      "-2.5183907\n",
      "0.47040063\n",
      "0.7125498\n",
      "0.89137805\n",
      "0.5321365\n",
      "0.5104127\n",
      "0.65745556\n",
      "0.35866994\n",
      "-0.5511819\n",
      "0.75648373\n",
      "-1.9447939\n",
      "0.4308179\n",
      "0.83313274\n",
      "0.69246244\n",
      "0.36251897\n",
      "0.8302655\n",
      "0.6307131\n",
      "0.5297231\n",
      "-2.2854843\n",
      "0.32284546\n",
      "0.34954953\n",
      "0.6238441\n",
      "0.75488603\n",
      "0.7337722\n",
      "0.84549546\n",
      "0.43027282\n",
      "0.5232671\n",
      "0.5053023\n",
      "0.32046354\n",
      "0.45418745\n",
      "0.7106086\n",
      "-0.64200866\n",
      "0.5889521\n",
      "0.47975492\n",
      "0.97052026\n",
      "-1.0596045\n",
      "-1.4675883\n",
      "0.45113498\n",
      "0.8109803\n",
      "0.32471126\n",
      "1.1265293\n",
      "0.6817775\n",
      "0.53258216\n",
      "0.79936934\n",
      "0.89891934\n",
      "0.056146085\n",
      "0.5838878\n",
      "0.66700625\n",
      "0.44666302\n",
      "0.5445996\n",
      "0.40978777\n",
      "0.5576003\n",
      "0.025943547\n",
      "-0.096067525\n",
      "0.64189583\n",
      "0.28928044\n",
      "0.81548274\n",
      "-0.8727213\n",
      "0.42909294\n",
      "-2.3168797\n",
      "0.26575503\n",
      "0.032077745\n",
      "0.97688377\n",
      "0.6694145\n",
      "-1.389541\n",
      "0.54680777\n",
      "-2.485579\n",
      "0.46800458\n",
      "0.59504586\n",
      "0.58866364\n",
      "0.42180127\n",
      "0.29811138\n",
      "0.710437\n",
      "0.6922128\n",
      "0.69361526\n",
      "0.79857683\n",
      "0.27419746\n",
      "0.9518757\n",
      "0.47976202\n",
      "0.62233365\n",
      "0.3637913\n",
      "-1.6710421\n",
      "-0.026407227\n",
      "0.38332283\n",
      "-0.17749555\n",
      "-0.69326377\n",
      "0.9426427\n",
      "-1.5138032\n",
      "0.5402427\n",
      "0.9765177\n",
      "0.32790196\n",
      "0.30904418\n",
      "-0.9088852\n",
      "0.6027922\n",
      "0.91299295\n",
      "0.9539684\n",
      "0.61080706\n",
      "-1.1381366\n",
      "-2.5265734\n",
      "0.83018804\n",
      "0.3535539\n",
      "-0.28427976\n",
      "0.7248369\n",
      "1.053297\n",
      "0.34707522\n",
      "-1.731753\n",
      "-1.8990728\n",
      "0.5439786\n",
      "0.9453865\n",
      "-0.5256534\n",
      "0.6708701\n",
      "-1.9310484\n",
      "0.40608996\n",
      "0.77573764\n",
      "0.75770605\n",
      "-2.388588\n",
      "0.11937997\n",
      "0.95555365\n",
      "0.7181296\n",
      "0.6567197\n",
      "0.8790463\n",
      "0.5446234\n",
      "-1.8627671\n",
      "0.35737222\n",
      "0.578063\n",
      "-1.88382\n",
      "1.0846817\n",
      "0.7026636\n",
      "-2.3976321\n",
      "0.41504526\n",
      "0.35690898\n",
      "-1.6184146\n",
      "0.7647041\n",
      "0.5539726\n",
      "0.60401917\n",
      "-0.44984585\n",
      "0.6125152\n",
      "-1.6411922\n",
      "0.7227811\n",
      "-1.8022772\n",
      "0.7461399\n",
      "-2.0941768\n",
      "1.2048843\n",
      "0.46682203\n",
      "0.5208927\n",
      "0.6131856\n",
      "0.9049902\n",
      "-1.3115824\n",
      "0.49867517\n",
      "-0.08974012\n",
      "-0.9523729\n",
      "1.0536643\n",
      "-0.14369848\n",
      "0.3092729\n",
      "-0.053163692\n",
      "0.7296574\n",
      "-2.3968105\n",
      "0.8437129\n",
      "0.51198405\n",
      "0.76083034\n",
      "-0.88152766\n",
      "-0.39670378\n",
      "0.793507\n",
      "-2.513563\n",
      "0.718762\n",
      "0.6915468\n",
      "0.8699682\n",
      "0.33839136\n",
      "0.78612256\n",
      "0.6811944\n",
      "0.5724322\n",
      "0.62824434\n",
      "-0.351353\n",
      "-1.6994467\n",
      "0.51927817\n",
      "0.5718473\n",
      "0.41337675\n",
      "0.4582169\n",
      "0.84076357\n",
      "-1.85344\n",
      "0.65039\n",
      "0.5503433\n",
      "0.7591567\n",
      "0.9403024\n",
      "0.6677691\n",
      "0.7161421\n",
      "0.87351394\n",
      "0.5027323\n",
      "-1.6313499\n",
      "0.6752222\n",
      "0.96918404\n",
      "0.5974248\n",
      "0.45063937\n",
      "0.73970854\n",
      "0.88723373\n",
      "0.2127262\n",
      "0.6434141\n",
      "0.5774738\n",
      "0.5248976\n",
      "0.939232\n",
      "-0.1221965\n",
      "0.004357815\n",
      "0.39286375\n",
      "0.65480655\n",
      "0.3239128\n",
      "0.62996083\n",
      "0.5088859\n",
      "0.2754723\n",
      "0.5543058\n",
      "0.48616254\n",
      "0.3940103\n",
      "0.37660432\n",
      "0.45028627\n",
      "0.726233\n",
      "0.65971434\n",
      "0.8682897\n",
      "0.52077794\n",
      "0.7726847\n",
      "0.38075066\n",
      "0.61774975\n",
      "1.0015923\n",
      "0.8410114\n",
      "0.4410149\n",
      "0.9589956\n",
      "0.46359187\n",
      "0.41229123\n",
      "-2.524279\n",
      "0.059111387\n",
      "-0.6055794\n",
      "0.83023643\n",
      "-2.0536442\n",
      "0.33608228\n",
      "-0.9633045\n",
      "-0.31668782\n",
      "0.4426396\n",
      "-1.0469275\n",
      "-0.03981647\n",
      "0.62388974\n",
      "1.0331032\n",
      "0.86444366\n",
      "0.881747\n",
      "-1.4262838\n",
      "-0.5864129\n",
      "0.53755057\n",
      "0.57087487\n",
      "-1.9732213\n",
      "0.7679723\n",
      "0.8704566\n",
      "0.83479166\n",
      "0.25536114\n",
      "0.5842376\n",
      "-2.1014452\n",
      "0.42809516\n",
      "0.5186018\n",
      "-1.8614138\n",
      "0.80581427\n",
      "0.97843885\n",
      "0.5916393\n",
      "0.34478468\n",
      "0.7506388\n",
      "0.6636745\n",
      "0.4553861\n",
      "0.74932545\n",
      "0.6673313\n",
      "0.28048685\n",
      "0.49512637\n",
      "-0.36073866\n",
      "0.6473623\n",
      "0.45903373\n",
      "0.070364326\n",
      "0.37602913\n",
      "0.42469287\n",
      "0.99097824\n",
      "0.49234217\n",
      "0.6062536\n",
      "0.90987754\n",
      "-1.2564896\n",
      "-1.2676557\n",
      "0.5680871\n",
      "0.5859058\n",
      "0.75719875\n",
      "0.32047296\n",
      "0.30811167\n",
      "0.30986714\n",
      "0.6511596\n",
      "0.4637162\n",
      "0.42838836\n",
      "0.47663993\n",
      "-2.3350027\n",
      "0.5208696\n",
      "0.5393385\n",
      "-1.0746031\n",
      "-0.88676727\n",
      "0.7338476\n",
      "0.53433573\n",
      "0.52535635\n",
      "0.75473565\n",
      "0.6054519\n",
      "0.4946968\n",
      "0.432595\n",
      "0.6048593\n",
      "-0.4416151\n",
      "0.6995406\n",
      "0.93021417\n",
      "1.1899003\n",
      "-1.6481715\n",
      "0.7554835\n",
      "0.6488026\n",
      "0.70104706\n",
      "0.47268385\n",
      "0.3480466\n",
      "0.528136\n",
      "0.8619245\n",
      "0.57901406\n",
      "0.5240834\n",
      "0.50171775\n",
      "0.6625042\n",
      "0.4481429\n",
      "0.6075006\n",
      "0.5224334\n",
      "-1.164695\n",
      "0.7677222\n",
      "0.96817434\n",
      "0.104270995\n",
      "0.18515936\n",
      "-1.3569928\n",
      "0.6433115\n",
      "0.2050794\n",
      "0.45801115\n",
      "0.58835673\n",
      "0.7452874\n",
      "0.7996049\n",
      "0.8477311\n",
      "-1.7615716\n",
      "0.34556365\n",
      "0.9565202\n",
      "0.87272894\n",
      "0.61285627\n",
      "0.5963927\n",
      "-0.9982335\n",
      "0.8535502\n",
      "0.7639131\n",
      "-2.4727595\n",
      "0.7427483\n",
      "1.0536731\n",
      "0.3151945\n",
      "0.6837322\n",
      "-0.40941733\n",
      "0.39810425\n",
      "0.92522895\n",
      "0.9532646\n",
      "-1.6161742\n",
      "0.7936115\n",
      "0.9786651\n",
      "0.5832738\n",
      "0.8958348\n",
      "0.9428139\n",
      "0.94413126\n",
      "0.30411047\n",
      "0.5705432\n",
      "-0.66027653\n",
      "-1.0243301\n",
      "0.7937467\n",
      "0.87137127\n",
      "0.5994164\n",
      "0.5939602\n",
      "0.61404\n",
      "0.72899425\n",
      "-1.7534459\n",
      "0.49563688\n",
      "0.49796295\n",
      "0.8646202\n",
      "0.3933198\n",
      "0.62293845\n",
      "0.7900205\n",
      "-0.44675353\n",
      "-0.9341535\n",
      "0.60801464\n",
      "1.0959469\n",
      "0.5109634\n",
      "0.6595958\n",
      "0.65759647\n",
      "0.4795887\n",
      "0.29358247\n",
      "-1.989111\n",
      "-0.7047024\n",
      "0.4592567\n",
      "0.32631117\n",
      "0.33290172\n",
      "1.0724392\n",
      "-0.0024263412\n",
      "0.6678644\n",
      "0.6439393\n",
      "-0.9679879\n",
      "1.2819923\n",
      "0.7744933\n",
      "0.5507922\n",
      "1.089634\n",
      "0.9348177\n",
      "0.79425174\n",
      "0.9485898\n",
      "0.41699672\n",
      "0.80545795\n",
      "0.27496165\n",
      "0.6428533\n",
      "0.58067924\n",
      "0.15598464\n",
      "-1.7983806\n",
      "0.87683856\n",
      "0.9929197\n",
      "0.48180312\n",
      "0.37695193\n",
      "0.88606155\n",
      "0.8592216\n",
      "-2.0892956\n",
      "0.4753641\n",
      "-0.633103\n",
      "0.56308323\n",
      "-0.11760778\n",
      "0.85135555\n",
      "0.4868288\n",
      "0.9929893\n",
      "0.9022366\n",
      "0.6783623\n",
      "-1.2289534\n",
      "0.3093629\n",
      "0.6557365\n",
      "0.38131684\n",
      "0.9218384\n",
      "0.6048819\n",
      "0.46099895\n",
      "0.6087344\n",
      "0.735815\n",
      "0.75274265\n",
      "0.32319927\n",
      "-0.9030918\n",
      "-2.518907\n",
      "0.75856805\n",
      "0.90380955\n",
      "-2.1206913\n",
      "0.9017217\n",
      "0.50638425\n",
      "0.8916068\n",
      "-0.64062864\n",
      "0.41002643\n",
      "0.36688942\n",
      "0.8072306\n",
      "0.5834206\n",
      "0.5287006\n",
      "1.005621\n",
      "0.47452962\n",
      "0.8067503\n",
      "1.0420198\n",
      "-2.3656769\n",
      "0.936067\n",
      "0.56077355\n",
      "0.85026693\n",
      "0.7850113\n",
      "0.5979631\n",
      "0.7976179\n",
      "0.38316137\n",
      "0.5893528\n",
      "0.79368806\n",
      "-1.1184821\n",
      "0.60889006\n",
      "0.31945384\n",
      "0.6874049\n",
      "0.36579967\n",
      "-0.012838677\n",
      "0.54606444\n",
      "-0.098949\n",
      "-2.3060348\n",
      "1.0699047\n",
      "0.38028073\n",
      "0.8614222\n",
      "0.5629365\n",
      "0.8699702\n",
      "0.8058522\n",
      "0.48350918\n",
      "0.6433877\n",
      "0.69456625\n",
      "0.770536\n",
      "-0.7410396\n",
      "0.671983\n",
      "0.51085246\n",
      "1.0305761\n",
      "0.7062853\n",
      "-0.6432841\n",
      "0.17468742\n",
      "-0.57454944\n",
      "0.27637503\n",
      "0.4291106\n",
      "0.6690131\n",
      "-0.4404424\n",
      "0.7140765\n",
      "0.18904072\n",
      "0.7369964\n",
      "0.33200288\n",
      "0.88455534\n",
      "0.6668175\n",
      "0.51455843\n",
      "-1.9224813\n",
      "-2.4058726\n",
      "0.36655247\n",
      "0.8249681\n",
      "-0.0037203282\n",
      "0.53019977\n",
      "-0.27467448\n",
      "0.27340487\n",
      "0.93645096\n",
      "-1.1798235\n",
      "-0.4229108\n",
      "0.38514358\n",
      "0.6409537\n",
      "0.08743802\n",
      "0.8027508\n",
      "0.9714545\n",
      "-1.4527504\n",
      "0.8408927\n",
      "0.3576507\n",
      "0.9477806\n",
      "0.44435585\n",
      "0.85400474\n",
      "-1.7258973\n",
      "0.21339512\n",
      "0.65944135\n",
      "-1.2571257\n",
      "0.6895968\n",
      "-0.8325773\n",
      "-0.9556626\n",
      "0.7259467\n",
      "0.6511778\n",
      "0.5344414\n",
      "0.61494404\n",
      "0.4733107\n",
      "0.3075415\n",
      "0.5891608\n",
      "0.68914574\n",
      "0.5338904\n",
      "0.6613335\n",
      "0.4663204\n",
      "0.7255958\n",
      "1.2196087\n",
      "0.67241484\n",
      "-2.4886756\n",
      "0.62241\n",
      "0.3693865\n",
      "-0.78956443\n",
      "0.45897722\n",
      "0.1782012\n",
      "-0.5239432\n",
      "0.58940977\n",
      "0.71713364\n",
      "0.69081914\n",
      "0.3965081\n",
      "0.47577727\n",
      "0.59552306\n",
      "0.48762834\n",
      "0.8532393\n",
      "0.44356567\n",
      "0.24171418\n",
      "0.427463\n",
      "-2.3291137\n",
      "0.96450675\n",
      "0.37343043\n",
      "0.68103635\n",
      "0.37048453\n",
      "0.31088066\n",
      "0.7845648\n",
      "0.54382646\n",
      "1.0369025\n",
      "0.4075237\n",
      "-1.7530638\n",
      "0.5566251\n",
      "-1.931398\n",
      "0.5758574\n",
      "-0.11511692\n",
      "0.6064721\n",
      "0.5711811\n",
      "0.69908303\n",
      "0.4282384\n",
      "0.3950094\n",
      "-1.0548974\n",
      "0.51418465\n",
      "0.77711785\n",
      "0.46997994\n",
      "0.7609761\n",
      "-2.5077226\n",
      "0.42120308\n",
      "0.6678488\n",
      "0.7884385\n",
      "0.54063064\n",
      "0.7146429\n",
      "0.45613664\n",
      "0.6532181\n",
      "0.6931368\n",
      "-2.529323\n",
      "-0.9046064\n",
      "0.5938258\n",
      "0.6258174\n",
      "-1.9480387\n",
      "0.5674099\n",
      "0.77114356\n",
      "0.24768189\n",
      "-0.8926416\n",
      "-2.4577696\n",
      "-0.08898424\n",
      "0.7486554\n",
      "0.5365678\n",
      "-0.35151634\n",
      "0.86626923\n",
      "-1.6273117\n",
      "-2.0758228\n",
      "-1.2152853\n",
      "0.5979576\n",
      "0.90384305\n",
      "-0.069139615\n",
      "-2.0940862\n",
      "0.9197434\n",
      "-0.3392014\n",
      "-1.4105172\n",
      "-1.0910649\n",
      "0.6031978\n",
      "0.7235616\n",
      "0.50178295\n",
      "0.6365447\n",
      "0.2408343\n",
      "0.4458382\n",
      "-2.1923575\n",
      "0.8164755\n",
      "0.8887415\n",
      "0.87851\n",
      "0.47434372\n",
      "-1.8889399\n",
      "0.5761646\n",
      "0.71876436\n",
      "0.7187776\n",
      "0.40618783\n",
      "0.14658454\n",
      "0.582196\n",
      "0.59330684\n",
      "0.5526437\n",
      "0.4620123\n",
      "-2.3907003\n",
      "-0.45506588\n",
      "0.44126248\n",
      "-0.18082431\n",
      "0.62098515\n",
      "-0.24627672\n",
      "1.1330594\n",
      "0.8709806\n",
      "-0.7054695\n",
      "0.6334458\n",
      "-0.2927239\n",
      "0.29563808\n",
      "0.67764616\n",
      "0.609213\n",
      "0.5913631\n",
      "0.5393811\n",
      "0.4477679\n",
      "0.49798065\n",
      "0.8962493\n",
      "-1.7847921\n",
      "0.56425333\n",
      "0.36544943\n",
      "1.1085666\n",
      "0.36679137\n",
      "0.58787465\n",
      "0.6744925\n",
      "0.35404253\n",
      "0.89898765\n",
      "0.7464954\n",
      "0.52402985\n",
      "0.46709317\n",
      "0.66748005\n",
      "0.25648502\n",
      "0.6140152\n",
      "0.5237313\n",
      "0.65427536\n",
      "-0.5826626\n",
      "0.040450037\n",
      "-0.15657088\n",
      "0.74463916\n",
      "1.0701258\n",
      "-0.83768314\n",
      "1.0010377\n",
      "0.6990379\n",
      "0.7295978\n",
      "1.0150553\n",
      "-2.435201\n",
      "0.61261916\n",
      "0.15928987\n",
      "0.9316921\n",
      "0.605587\n",
      "0.8329524\n",
      "0.59515756\n",
      "0.92465603\n",
      "0.49391568\n",
      "1.1375477\n",
      "-1.939114\n",
      "0.18846592\n",
      "0.3287015\n",
      "-0.22603512\n",
      "0.7138969\n",
      "-0.098858275\n",
      "0.3271057\n",
      "0.59761477\n",
      "0.66042984\n",
      "0.05078751\n",
      "0.81403184\n",
      "1.1733389\n",
      "0.86795974\n",
      "0.67061394\n",
      "0.7463477\n",
      "0.6944309\n",
      "0.60098153\n",
      "0.17807704\n",
      "0.8547059\n",
      "0.975616\n",
      "0.4177643\n",
      "-0.1871498\n",
      "0.08467662\n",
      "0.6221494\n",
      "0.115235925\n",
      "0.2771982\n",
      "0.67540383\n",
      "-2.5296009\n",
      "0.8155656\n",
      "0.6046707\n",
      "0.7072871\n",
      "-0.93600374\n",
      "0.46909416\n",
      "0.53308386\n",
      "0.80911136\n",
      "0.7928237\n",
      "0.56881726\n",
      "0.59789044\n",
      "0.5119542\n",
      "0.1153332\n",
      "0.73237234\n",
      "0.5469415\n",
      "0.6598726\n",
      "0.733405\n",
      "0.84667885\n",
      "-2.3979247\n",
      "-0.72618777\n",
      "0.4072591\n",
      "0.9604409\n",
      "0.5682469\n",
      "0.4230427\n",
      "0.59101117\n",
      "-2.4273765\n",
      "-1.9251132\n",
      "0.7889713\n",
      "0.76789683\n",
      "0.62152606\n",
      "0.5744173\n",
      "-0.1681107\n",
      "0.38643456\n",
      "0.66439235\n",
      "0.3177805\n",
      "0.76691824\n",
      "0.5281774\n",
      "0.6009081\n",
      "0.63182783\n",
      "0.42725718\n",
      "0.79492193\n",
      "-0.14447571\n",
      "0.848488\n",
      "-0.53783315\n",
      "0.5916202\n",
      "0.2627939\n",
      "0.30953664\n",
      "0.099164456\n",
      "0.39062893\n",
      "-2.3122973\n",
      "0.5524762\n",
      "0.5523728\n",
      "0.20107362\n",
      "0.99466\n",
      "-0.57148063\n",
      "0.6741835\n",
      "0.39132178\n",
      "-1.4706757\n",
      "-0.0005469173\n",
      "-0.8546065\n",
      "0.75959677\n",
      "0.49287093\n",
      "-0.44932052\n",
      "0.4443618\n",
      "0.9631871\n",
      "0.6889215\n",
      "0.75543255\n",
      "0.5234861\n",
      "0.9316741\n",
      "0.9501388\n",
      "0.7965535\n",
      "0.6928774\n",
      "0.89499724\n",
      "-0.2616945\n",
      "0.96683383\n",
      "0.8763479\n",
      "0.4867605\n",
      "0.82254493\n",
      "0.4291557\n",
      "0.3913738\n",
      "0.34871596\n",
      "1.0866084\n",
      "0.39008898\n",
      "0.7312708\n",
      "0.488465\n",
      "-1.5780945\n",
      "0.6703873\n",
      "-2.3405483\n",
      "-1.8812937\n",
      "0.34205556\n",
      "0.4757281\n",
      "0.46945012\n",
      "-0.72522223\n",
      "0.35747552\n",
      "-0.9822277\n",
      "0.8417046\n",
      "-0.6398971\n",
      "0.14211467\n",
      "0.9276258\n",
      "0.67136645\n",
      "0.92775345\n",
      "0.9690088\n",
      "0.7313637\n",
      "0.75077415\n",
      "0.91278434\n",
      "-1.0144973\n",
      "0.4336337\n",
      "0.8036444\n",
      "0.77975404\n",
      "0.6848912\n",
      "0.50135565\n",
      "0.40221924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "endpointName = 'dnn-2020-07-31-23-40-40-767' # Your endpoint name that was created in \"Deploy the model\" section\n",
    "\n",
    "from pickle import load\n",
    "\n",
    "# Process and prepare the data\n",
    "def transform_data(test_x):\n",
    "    test_x = test_x.dropna()\n",
    "    test_x = test_x.astype('float32')\n",
    "        \n",
    "    # Feature Scaling\n",
    "    scaler = load(open('opt/ml/model/scaler.pkl', 'rb'))\n",
    "    test_x = scaler.fit_transform(test_x)\n",
    "    return pd.DataFrame(test_x)\n",
    "\n",
    "test_X = pd.read_csv('df_test.csv')\n",
    "\n",
    "test_X = transform_data(test_X)\n",
    "\n",
    "\n",
    "test_file = io.StringIO()\n",
    "test_X.to_csv(test_file, header=None, index=None)\n",
    "\n",
    "# Talk to SageMaker\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpointName,\n",
    "    Body=test_file.getvalue(),\n",
    "    ContentType='text/csv',\n",
    "    Accept='Accept'\n",
    ")\n",
    "\n",
    "print(response['Body'].read().decode('ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar cvfz container_hpo.tar.gz *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: ann-churn-2018-05-27-18-29-21-010\n"
     ]
    }
   ],
   "source": [
    "# sess.delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
